{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"helper_functions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from keras import backend as K\n","\n","path = './drive/MyDrive/cs109b_final_project/'"],"metadata":{"id":"pgAa1vlgQpzO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper Functions"],"metadata":{"id":"ec-NCjaIOgLb"}},{"cell_type":"markdown","source":["### Checking for Data Leakage"],"metadata":{"id":"2qo0GJtUNrjx"}},{"cell_type":"code","source":["# Checks for leakage between two dataframes\n","def has_leakage(df_1, df_2, patient_id):\n","  \"\"\"\n","  Returns True if there are patients common to df_1 and df_2\n","\n","  \"\"\"\n","  # Get unique patient ids \n","  df_1_patients = set(df_1[patient_id].values)\n","  df_2_patients = set(df_2[patient_id].values)\n","\n","  # Get patients common to both dataframes\n","  common_patients = df_1_patients.intersection(df_2_patients)\n","\n","  # Return True if common_patients is non empty\n","  if len(common_patients) > 0:\n","    return True\n","  \n","  return False"],"metadata":{"id":"mF_xHnEPNqMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loss Functions"],"metadata":{"id":"D8vqp2OuOGeC"}},{"cell_type":"code","source":["# Get class frequencies - used to get pos_weights, neg_weights for Weighted loss function\n","def get_class_frequencies(y_cols):\n","  \"\"\"\n","  Returns positive and negative frequencies for each class.\n","\n","  Args:\n","    y_cols (np.array): array of labels, size (num_observations, num_classes) i.e train_generator.labels\n","\n","  Returns:\n","    pos_freqs (np.array): array of positive frequencies for each class, size (num_classes)\n","    neg_freqs (np.array): array of negative frequencies for each class, size (num_classes)\n","\n","  \"\"\"\n","  \n","  pos_freqs = np.mean(y_cols, axis=0) \n","  neg_freqs = 1 - pos_freqs\n","\n","  return pos_freqs, neg_freqs2"],"metadata":{"id":"pg9EfAe7PAw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use case of get class_frequences on train_relabeled.csv\n","df = pd.read_csv(path + 'label_data/train_relabeled.csv')\n","labels = df.drop('Path', axis = 1).values\n","\n","pos_freqs, neg_freqs = get_class_frequencies(labels)\n","print(f\"Positive Frequencies: {pos_freqs}\")\n","print(f\"Negative Frequencies: {neg_freqs}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROcJf-8QUAxp","executionInfo":{"status":"ok","timestamp":1651286264288,"user_tz":-480,"elapsed":297,"user":{"displayName":"Alex Lim","userId":"07337692984168731164"}},"outputId":"ac36f5cb-7b13-48ba-d27c-ea1cda1b39b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive Frequencies: [0.08045662 0.0537932  0.19299046 0.05120796 0.23294504 0.10553849\n"," 0.11787666 0.17728641 0.10560946 0.11358821 0.09973945 0.11114491\n"," 0.11526101 0.15459716]\n","Negative Frequencies: [0.91954338 0.9462068  0.80700954 0.94879204 0.76705496 0.89446151\n"," 0.88212334 0.82271359 0.89439054 0.88641179 0.90026055 0.88885509\n"," 0.88473899 0.84540284]\n"]}]},{"cell_type":"code","source":["# Weighted loss function: pos_weights = negative frequencies, neg_weights = positive frequencies (from lecture slides)\n","\n","def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n","  \"\"\"\n","  Return weighted loss function given negative weights and positive weights.\n","\n","  Args:\n","    pos_weights (np.array): array of positive weights for each class, size (num_classes)\n","    neg_weights (np.array): array of negative weights for each class, size (num_classes)\n","\n","  Returns:\n","    weighted_loss (function): weighted loss function.\n","  \"\"\"\n","  def weighted_loss(y_true, y_pred):\n","    \"\"\"\n","    Return weighted loss value.\n","\n","    Args:\n","      y_true (Tensor): Tensor of true labels, size is (num_examples, num classes)\n","      y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num classes)\n","\n","    Returns:\n","      loss (float): overall scalar loss summed across all classes.\n","    \"\"\"\n","    # initialize loss to zero\n","    loss = 0.0\n","\n","    for i in range(len(pos_weights)):\n","      # for each class, add average weighted loss for that class\n","      loss += -1. * K.mean(\n","          pos_weights[i] * y_true[:,i] * K.log(y_pred[:,i] + epsilon) + \\\n","          neg_weights[i] * (1 - y_true[:,i]) * K.log(1 - y_pred[:,i] + epsilon)\n","      )\n","\n","    return loss\n","\n","  return weighted_loss"],"metadata":{"id":"NGZ7GtY_OFsZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use case of get_weighted_loss - both losses should be the same if weighted correctly\n","session = K.get_session()\n","with session.as_default() as session:\n","  pos_weights = neg_freqs\n","  neg_weights = pos_freqs\n","  preds_1 = 0.7 * np.ones(labels.shape)\n","  preds_2 = 0.3 * np.ones(labels.shape)\n","  loss_func = get_weighted_loss(pos_weights, neg_weights)\n","  print(f'preds_1 loss: {loss_func(labels, preds_1).eval():.4f}')\n","  print(f'preds_2 loss: {loss_func(labels, preds_2).eval():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59WLwGcOYpeg","executionInfo":{"status":"ok","timestamp":1651288144415,"user_tz":-480,"elapsed":1357,"user":{"displayName":"Alex Lim","userId":"07337692984168731164"}},"outputId":"55ce60ac-4693-43bd-a4bc-a85c5abcfddc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["preds_1 loss: 2.2919\n","preds_2 loss: 2.2919\n"]}]}]}